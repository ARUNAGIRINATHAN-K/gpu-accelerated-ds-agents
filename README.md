<div align="center">

![](GPU.png)

*Autonomous data science workflows with 10-50√ó GPU speedup*

[![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![RAPIDS](https://img.shields.io/badge/RAPIDS-cuDF%20%7C%20cuML-76B900?style=for-the-badge&logo=nvidia&logoColor=white)](https://rapids.ai/)
[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-blue?style=for-the-badge)](LICENSE)

</div>

---

<div align="center">

*A production-ready system for autonomous data science leveraging **NVIDIA CUDA** and **RAPIDS** on Google Colab's free GPUs. Run complete ML pipelines from EDA to deployment with **zero API costs** using local LLM orchestration.*

---

## Features

<table>
<tr>
<td width="50%">

### Autonomous Agents
- **EDA Agent** - Auto data profiling
- **Modeling Agent** - Multi-algorithm training
- **Viz Agent** - Smart visualizations
- **Report Agent** - Full documentation

</td>
<td width="50%">

### GPU Acceleration
- **10-50√ó faster** than CPU
- Free Tesla T4/V100 on Colab
- RAPIDS cuDF & cuML
- XGBoost GPU support

</td>
</tr>
<tr>
<td width="50%">

### Local LLM Orchestrator
- Zero API costs
- Llama 2 / Mistral / Phi
- Intelligent workflow planning
- Context-aware decisions

</td>
<td width="50%">

### Hybrid Architecture
- Local Streamlit UI
- Cloud GPU execution
- Seamless data transfer
- Flexible deployment

</td>
</tr>
</table>

## Tech Stack

| Category | Technologies |
|----------|-------------|
| **GPU Computing** | ![CUDA](https://img.shields.io/badge/CUDA-76B900?style=flat&logo=nvidia) ![RAPIDS](https://img.shields.io/badge/RAPIDS-76B900?style=flat) |
| **ML Frameworks** | ![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&logo=pytorch&logoColor=white) ![XGBoost](https://img.shields.io/badge/XGBoost-337AB7?style=flat) ![cuML](https://img.shields.io/badge/cuML-76B900?style=flat) |
| **LLM Stack** | ![Transformers](https://img.shields.io/badge/ü§ó_Transformers-FFD21E?style=flat) ![Llama](https://img.shields.io/badge/Llama_2-0467DF?style=flat) |
| **Data Processing** | ![cuDF](https://img.shields.io/badge/cuDF-76B900?style=flat) ![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat&logo=pandas) |
| **Visualization** | ![Plotly](https://img.shields.io/badge/Plotly-3F4F75?style=flat&logo=plotly) ![Matplotlib](https://img.shields.io/badge/Matplotlib-11557c?style=flat) |
| **UI/Platform** | ![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=flat&logo=streamlit&logoColor=white) ![Colab](https://img.shields.io/badge/Colab-F9AB00?style=flat&logo=googlecolab&logoColor=white) |

</div>

---

<div align="center">

## Benchmarks

| Operation | CPU Time | GPU Time | Speedup |
|-----------|----------|----------|---------|
| Load 10M rows | 45s | 2.3s | **19.6√ó** |
| Preprocessing | 120s | 6.5s | **18.5√ó** |
| Correlation | 35s | 1.2s | **29.2√ó** |
| XGBoost | 180s | 12s | **15.0√ó** |
| **Full Pipeline** | **380s** | **22s** | **17.3√ó** |

*Tesla T4 GPU vs Intel i7-10700K CPU*

</div>

---

<div align="center">

**Built with ‚ù§Ô∏è for the data science community**

[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/ARUNAGIRINATHAN-K)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/arunagirinathan-k/)


</div>
