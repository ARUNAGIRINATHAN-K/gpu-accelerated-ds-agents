# ğŸ“Š Data Analyst Agent

An **AI-powered Data Analyst Assistant** that helps users analyze datasets in natural language.
Built with **HTML, Bootstrap, and JavaScript (frontend)** and **Python (Flask/FastAPI + Pydantic-AI + Pandas/Polars)** as backend.

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python&logoColor=white)
![Flask](https://img.shields.io/badge/Flask-2.0+-black?logo=flask)
![FastAPI](https://img.shields.io/badge/FastAPI-0.95+-green?logo=fastapi)
![Pydantic](https://img.shields.io/badge/Pydantic-AI-orange?logo=pydantic)
![Pandas](https://img.shields.io/badge/Pandas-1.5+-blue?logo=pandas)
![Bootstrap](https://img.shields.io/badge/Bootstrap-5-563D7C?logo=bootstrap&logoColor=white)
![JavaScript](https://img.shields.io/badge/JavaScript-ES6-yellow?logo=javascript&logoColor=black)
![Chart.js](https://img.shields.io/badge/Chart.js-FF6384?logo=chartdotjs)
![License](https://img.shields.io/github/license/your-username/data-analyst-agent)
![Build](https://img.shields.io/badge/Build-Passing-brightgreen)


The system allows users to:

* Upload datasets (CSV/Excel).
* Ask natural language questions (e.g., *â€œShow me the average revenue by region over timeâ€*).
* Receive structured insights and visualizations (tables, charts).

---

## ğŸš€ Features

* **Dataset Upload**: Accepts CSV/Excel files from users.
* **Natural Language Querying**: Users type plain-English questions.
* **Pydantic-AI Schema Validation**: Queries are translated into structured, validated schemas.
* **Data Analysis Engine**: Pandas/Polars executes filtering, grouping, aggregation, and summaries.
* **Visualization**: Frontend renders results using **Bootstrap tables** and **Chart.js/D3.js** charts.
* **RESTful API**: Flask/FastAPI backend for query processing and dataset management.

---

## ğŸ—ï¸ Architecture

### High-Level Flow

1. **Frontend (HTML + Bootstrap + JS)**

   * UI for file upload and query input.
   * Displays analysis results and charts.

2. **Backend (Python with Flask/FastAPI)**

   * Handles dataset uploads and query requests.
   * Passes user queries to reasoning engine.

3. **Reasoning Layer (Pydantic-AI)**

   * Translates natural language into structured schemas (e.g., `AggregationRequest`, `SummaryRequest`, `VisualizationRequest`).
   * Ensures valid queries.

4. **Execution Engine (Pandas/Polars)**

   * Executes requested analysis on dataset.
   * Returns structured JSON response.

5. **Frontend Rendering**

   * Uses Chart.js/D3.js for visualization.
   * Uses Bootstrap tables/cards for results display.

---

## ğŸ“Š EDA Project Phases

| Phase | Name        | Purpose                                                                 |
|-------|-------------|-------------------------------------------------------------------------|
| 1     | Foundation  | Establish the groundwork: load data, inspect structure, and set up the environment. |
| 2     | Refinement  | Clean and preprocess data: handle missing values, outliers, and ensure consistency. |
| 3     | Lens        | Focus on individual features: explore distributions, summary statistics, and categorical counts. |
| 4     | Connections | Analyze relationships: correlations, scatterplots, heatmaps, and multivariate insights. |
| 5     | Discovery   | Derive insights: feature engineering, highlight patterns, and prepare data for modeling. |


---

## ğŸ”¹ Architecture Overview

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚        Frontend (UI)        â”‚
                â”‚  HTML + Bootstrap + JS      â”‚
                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
 User Uploads â†’ â”‚ File Upload (CSV/Excel)     â”‚
 User Queries â†’ â”‚ Text Input (Natural Query)  â”‚
                â”‚ Visualization (Chart.js)    â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚     â”‚
          (AJAX/Fetch API)  â”‚     â”‚  (JSON Response)
                            â”‚     â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚        Backend API          â”‚
                â”‚ Flask / FastAPI (Python)    â”‚
                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
   Routes:      â”‚ /upload   â†’ receive dataset â”‚
                â”‚ /analyze  â†’ interpret query â”‚
                â”‚ /visualizeâ†’ return chart    â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚     â”‚
                            â”‚     â”‚ (structured schema)
                            â”‚     â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Reasoning & Validation    â”‚
                â”‚    Pydantic-AI Models       â”‚
                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                â”‚ Validate Query Intent       â”‚
                â”‚ (Aggregation, Summary, Viz) â”‚
                â”‚ Ensure schema correctness   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚     â”‚
                            â”‚     â”‚ (clean instructions)
                            â”‚     â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚      Execution Engine       â”‚
                â”‚   Pandas / Polars in Python â”‚
                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
                â”‚ Process dataset (filter,    â”‚
                â”‚ group, aggregate, describe) â”‚
                â”‚ Return table/chart data     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚     â”‚
                            â”‚     â”‚ (results as JSON)
                            â”‚     â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚        Frontend JS          â”‚
                â”‚  Renders results in DOM     â”‚
                â”‚  Bootstrap table / Chart.js â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¹ Key Flow

1. **Frontend (HTML/Bootstrap/JS)**

   * User uploads dataset & submits query.
   * Query + dataset metadata sent via AJAX to backend.

2. **Backend (Flask/FastAPI)**

   * Handles API routes (`/upload`, `/analyze`).
   * Passes user query to **Pydantic-AI models**.

3. **Pydantic-AI (Reasoning Layer)**

   * Interprets query into structured schema (e.g., `AggregationRequest`).
   * Ensures validity (no nonsense like â€œaverage of namesâ€).

4. **Execution Engine (Pandas/Polars)**

   * Runs requested operation on dataset.
   * Returns structured JSON with results or chart data.

5. **Frontend (JS + Bootstrap)**

   * Receives JSON â†’ Renders tables with Bootstrap and charts with Chart.js.


## ğŸ”§ Tech Stack

### Frontend

* **HTML5, CSS3**
* **Bootstrap 5** (responsive layout, styling)
* **JavaScript (ES6)**
* **Chart.js / D3.js** (visualizations)

### Backend

* **Python 3.10+**
* **Flask / FastAPI** (REST API)
* **Pydantic-AI** (structured schema validation)
* **Pandas / Polars** (data analysis)

---

## âš™ï¸ API Endpoints

| Endpoint     | Method | Description                        |
| ------------ | ------ | ---------------------------------- |
| `/upload`    | POST   | Upload dataset (CSV/Excel)         |
| `/analyze`   | POST   | Submit natural language query      |
| `/visualize` | GET    | Retrieve visualization config/data |

---

## ğŸ“‚ Project Structure

```
data-analyst-agent/
â”‚â”€â”€ backend/
â”‚   â”œâ”€â”€ app.py              # Flask/FastAPI entrypoint
â”‚   â”œâ”€â”€ models.py           # Pydantic schemas
â”‚   â”œâ”€â”€ analyzer.py         # Pandas/Polars execution engine
â”‚   â””â”€â”€ utils/              # Helpers (validation, parsing)
â”‚
â”‚â”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html          # Main UI page
â”‚   â”œâ”€â”€ styles.css          # Custom Bootstrap overrides
â”‚   â”œâ”€â”€ app.js              # JS logic (fetch API, rendering)
â”‚   â””â”€â”€ charts.js           # Chart rendering functions
â”‚
â”‚â”€â”€ datasets/               # Uploaded user datasets
â”‚â”€â”€ README.md               # Documentation
â”‚â”€â”€ requirements.txt        # Python dependencies
```

---

## ğŸ“– Example Workflow

1. User uploads `sales_data.csv`.
2. User enters query: *â€œWhat is the average revenue by country?â€*
3. Backend (via Pydantic-AI) translates into structured schema:

   ```json
   {
     "type": "AggregationRequest",
     "group_by": "country",
     "metric": "revenue",
     "agg_func": "mean"
   }
   ```
4. Execution engine (Pandas/Polars) computes results:

   ```
   Country   | Avg Revenue
   ----------|------------
   USA       | 45000
   UK        | 38000
   India     | 27000
   ```
5. Frontend renders:

   * Bootstrap **table** with computed values.
   * Chart.js **bar chart** of revenue by country.

---

## ğŸ“¦ Installation & Setup

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/ARUNAGIRINATHAN-K/Data-Analyst-Agent.git
cd data-analyst-agent
```

### 2ï¸âƒ£ Backend Setup

```bash
cd backend
pip install -r requirements.txt
```

Run the API server:

```bash
python app.py
```

### 3ï¸âƒ£ Frontend Setup

Open `frontend/index.html` in a browser (or serve with any static server).

---

## ğŸ”® Future Enhancements

* âœ… Context-aware conversations (query memory).
* âœ… Automated chart recommendations.
* âœ… Multi-dataset comparison.
* âœ… Role-based access (Analyst, Manager, Admin).
* âœ… Deployment on Docker, AWS, or Streamlit Cloud (for alternative prototyping).


